# -*- coding: utf-8 -*-
"""feature encoding and scaling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d2_q8C1bdUAExsTWBcPdFNt5wOLMFnsj
"""

# In a new file, e.g., src/feature_engineering.py

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from typing import Dict, Any, Union, Tuple

def preprocess_features(
    df: pd.DataFrame,
    target_variable: str,
    scaler_obj: StandardScaler = None,
    encoder_obj: OneHotEncoder = None
) -> Tuple[pd.DataFrame, StandardScaler, OneHotEncoder]:

    df_processed = df.copy()

    # --- Step 1: Separate Target from Features ---
    # This prevents the target from being scaled
    if target_variable in df_processed.columns:
        y = df_processed[target_variable]
        X = df_processed.drop(columns=[target_variable])
    else:
        X = df_processed
        y = None # No target in prediction data

    # --- Step 2: Identify column types in the feature set (X) ---
    numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    # --- Step 3: Handle Categorical Features (One-Hot Encoding) ---
    if encoder_obj is None: # First run: fit a new encoder
        print("Fitting a new OneHotEncoder.")
        encoder_obj = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')
        X_encoded_array = encoder_obj.fit_transform(X[categorical_cols])
    else: # Subsequent runs: use the existing encoder
        print("Using an existing OneHotEncoder.")
        X_encoded_array = encoder_obj.transform(X[categorical_cols])

    # Create a DataFrame with the new encoded columns
    encoded_cols = encoder_obj.get_feature_names_out(categorical_cols)
    X_encoded_df = pd.DataFrame(X_encoded_array, index=X.index, columns=encoded_cols)

    # --- Step 4: Handle Numerical Features (Standard Scaling) ---
    if scaler_obj is None: # First run: fit a new scaler
        print("Fitting a new StandardScaler.")
        scaler_obj = StandardScaler()
        X_scaled_array = scaler_obj.fit_transform(X[numeric_cols])
    else: # Subsequent runs: use the existing scaler
        print("Using an existing StandardScaler.")
        X_scaled_array = scaler_obj.transform(X[numeric_cols])

    # Create a DataFrame with the new scaled columns
    X_scaled_df = pd.DataFrame(X_scaled_array, index=X.index, columns=numeric_cols)

    # --- Step 5: Combine everything back together ---
    X_final = pd.concat([X_scaled_df, X_encoded_df], axis=1)

    # Add the target back in if it exists
    if y is not None:
        X_final[target_variable] = y

    return X_final, scaler_obj, encoder_obj

